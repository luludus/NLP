# Part1--教材教程
1. 吴恩达 coursera机器学习（机器学习基础，偏实践，没多少理论部分；课程代码用的matlab，网上有python代码，代码是机器学习相关的，现在深度学习貌似用不太到）
2. 吴恩达 cs229 （机器学习，理论性强；要快速上手的话可以晚点看）
3. 李沐  动手深度学习（深度学习入门，会学到pytorch）
4. cs224n （有一些NLP相关的经典模型算法，以及一些比较新的内容）
5. 深度学习教材：花书或者邱希鹏的神经网络与深度学习；

# Part2--论文项目
1. Attention Is All You Need （Transformer）
2. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding（BERT）
3. Deep Residual Learning for Image Recognition（RESNET）
4. Improving Language Understanding by Generative Pre-Training（GPT）
5. AN IMAGE IS WORTH 16X16 WORDS:TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE (CV相关的一篇）
6. Learning Transferable Visual Models From Natural Language Supervision（多模态的一篇）
7. Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing（Prompt的一篇综述）
## 项目
1.https://github.com/chatchat-space/langchain-ChatGLM（模型借助langchain，进行外部知识库加载问答）
2.https://github.com/ymcui/Chinese-LLaMA-Alpaca
3.https://github.com/mymusise/ChatGLM-Tuning（模型微调）

# Part3--方向
## COT方向基础论文：
1.Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
2.Large Language Models are Zero-Shot Reasoners
3.Why Johnny Can’t Prompt:How Non-AI Experts Try (and Fail) to Design LLM Prompts How Non-AI Experts Try (and Fail) to Design LLM Prompts
